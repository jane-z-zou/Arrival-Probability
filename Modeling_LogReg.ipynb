{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e83b7b17",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.10 from \"/Library/Frameworks/Python.framework/Versions/3.10/bin/python3\"\n  * The NumPy version is: \"1.23.1\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so, 0x0002): tried: '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64'))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mglob\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/__init__.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         missing_dependencies\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdependency\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_dependencies:\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to import required dependencies:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing_dependencies)\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m hard_dependencies, dependency, missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.10 from \"/Library/Frameworks/Python.framework/Versions/3.10/bin/python3\"\n  * The NumPy version is: \"1.23.1\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so, 0x0002): tried: '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-darwin.so' (mach-o file, but is an incompatible architecture (have 'arm64', need 'x86_64'))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, glob\n",
    "filename = os.path.join(os.getcwd(), \"FEATURE_ENGINEERING.txt\")\n",
    "df = pd.read_table(filename, low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1c38d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0324a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=df.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17caf531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f74ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e89983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list(df.iloc[:, 0:45].select_dtypes(include=\"float64\"))\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e0010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:,\"arr_ind_10\"]\n",
    "X = df.loc[:,feature_list]\n",
    "\n",
    "print(\"Number of examples: \" + str(X.shape[0]))\n",
    "print(\"\\nNumber of Features:\" + str(X.shape[1]))\n",
    "print(str(list(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c135d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3906a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_LR(X_train, y_train, X_test, y_test, c=1):\n",
    "    '''\n",
    "    Fit a Linear Regression classifier to the training data X_train, y_train.\n",
    "    Return the loss and accuracy of resulting predictions on the test set.\n",
    "    Parameters:\n",
    "        C = Factor that controls how much regularization is applied to the model.\n",
    "    '''\n",
    "     # 1. Create the  scikit-learn LogisticRegression model object below and assign to variable 'model'\n",
    "    model = LogisticRegression(C=c)\n",
    "  \n",
    "    # 2. Fit the model to the training data below\n",
    "    model.fit(X_train, y_train)  \n",
    "    \n",
    "    # 3. Make predictions on the test data using the predict_proba() method and assign the result to the \n",
    "    # variable 'probability_predictions' below\n",
    "    probability_predictions = model.predict_proba(X_test)\n",
    "  \n",
    "    # 4. Compute the log loss on 'probability_predictions' and save the result to the variable 'l_loss' below\n",
    "    l_loss = log_loss(y_test, probability_predictions)\n",
    "        \n",
    "    # 5. Make predictions on the test data using the predict() method and assign the result to the \n",
    "    # variable 'class_label_predictions' below\n",
    "    class_label_predictions = model.predict(X_test)\n",
    "        \n",
    "    # 6. Compute the accuracy score on 'class_label_predictions' and save the result to the variable 'acc_score' below\n",
    "    acc_score = accuracy_score(y_test, class_label_predictions)\n",
    "    \n",
    "    return l_loss, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f95b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = train_test_LR(X_train, y_train, X_test, y_test)\n",
    "print('Log loss: ' + str(loss))\n",
    "print('Accuracy: ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d79a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = [10**i for i in range(-10,10)]\n",
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7863361",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_cs = []\n",
    "acc_cs = []\n",
    "for i in range(20):\n",
    "    loss, acc = train_test_LR(X_train, y_train, X_test, y_test, c = cs[i])\n",
    "    ll_cs.append(loss)\n",
    "    acc_cs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc4e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7)) \n",
    "\n",
    "ax = sns.barplot(x=cs, y=ll_cs)\n",
    "g = ax.set_xticklabels([f'10^{i}' for i in range(-10,10)])\n",
    "ax.set_xlabel('Regularization HyperParameter: C')\n",
    "ax.set_ylabel('Log Loss')\n",
    "ax.set_ylim([0.58, 0.605])\n",
    "g = plt.title('Log Loss Test Performance by Regularization Weight C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4545a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "x = np.log10(cs)\n",
    "\n",
    "sns.lineplot(x=x, y=acc_cs, marker='o')\n",
    "\n",
    "plt.title(\"Accuracy Test Performance by Regularization Weight C'\")\n",
    "plt.xlabel(\"Regularization HyperParameter: C\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0a0a3d",
   "metadata": {},
   "source": [
    "10000 best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded4586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the  Scikit-learn LogisticRegression model object below and assign to variable 'model_default'\n",
    "model_default = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "model_default.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78291c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make predictions on the test data using the predict_proba() method\n",
    "proba_predictions_default = model_default.predict_proba(X_test)[:,1]\n",
    "\n",
    "# 2. Make predictions on the test data using the predict() method\n",
    "class_label_predictions_default = model_default.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca1f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, class_label_predictions_default, labels=[True,False]), columns=['Predicted: Arrival 10', 'Predicted: Not Arrival 10'],\n",
    "index=['Actual: Arrival 10', 'Actual: No Arrival 10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2edddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the  model object below and assign to variable 'model_best'\n",
    "model_best = LogisticRegression(max_iter=1000, C = 10000)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "model_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad8fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make predictions on the test data using the predict_proba() method\n",
    "proba_predictions_best = model_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "# 2. Make predictions on the test data using the predict() method\n",
    "class_label_predictions_best = model_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ded319",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, class_label_predictions_best, labels=[True,False]), columns=['Predicted: Arrival 10', 'Predicted: Not Arrival 10'],\n",
    "index=['Actual: Arrival 10', 'Actual: No Arrival 10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18045d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_default, recall_default, thresholds_default = precision_recall_curve(y_test, proba_predictions_default)\n",
    "precision_best, recall_best, thresholds_best = precision_recall_curve(y_test, proba_predictions_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c77648",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_default, tpr_default, thresholds_default = roc_curve(y_test,proba_predictions_default)\n",
    "fpr_best, tpr_best, thresholds_best = roc_curve(y_test, proba_predictions_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4849bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_default = auc(fpr_default, tpr_default)\n",
    "auc_best = auc(fpr_best, tpr_best)\n",
    "\n",
    "print(auc_default)\n",
    "print(auc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df63b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Note that k=5 is specifying that we want the top 5 features\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(X, y)\n",
    "filter = selector.get_support()\n",
    "top_5_features = X.columns[filter]\n",
    "\n",
    "print(\"Best 5 features:\")\n",
    "print(top_5_features)\n",
    "\n",
    "# Create new training and test data for features\n",
    "new_X_train = X_train[top_5_features]\n",
    "new_X_test = X_test[top_5_features]\n",
    "\n",
    "\n",
    "# Initialize a LogisticRegression model object with the best value of hyperparameter C \n",
    "# The model object should be named 'model'\n",
    "# Note: Supply max_iter=1000 as an argument when creating the model object\n",
    "model = LogisticRegression(max_iter=1000, C=2.7029857954888498e-05)\n",
    "\n",
    "\n",
    "# Fit the model to the new training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use the predict_proba() method to use your model to make predictions on the new test data \n",
    "# Save the values of the second column to a list called 'proba_predictions'\n",
    "proba_predictions = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    \n",
    "# Compute the auc-roc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, proba_predictions)\n",
    "auc_result = auc(fpr, tpr)\n",
    "print(auc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab533dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list(df.iloc[:, 0:55].select_dtypes(include=\"float64\"))\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df35cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:,\"arr_ind_20\"]\n",
    "X = df.loc[:,feature_list]\n",
    "\n",
    "print(\"Number of examples: \" + str(X.shape[0]))\n",
    "print(\"\\nNumber of Features:\" + str(X.shape[1]))\n",
    "print(str(list(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1758122",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b7eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbff048",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = train_test_LR(X_train, y_train, X_test, y_test)\n",
    "print('Log loss: ' + str(loss))\n",
    "print('Accuracy: ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9742f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_cs = []\n",
    "acc_cs = []\n",
    "for i in range(20):\n",
    "    loss, acc = train_test_LR(X_train, y_train, X_test, y_test, c = cs[i])\n",
    "    ll_cs.append(loss)\n",
    "    acc_cs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99eef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7)) \n",
    "\n",
    "ax = sns.barplot(x=cs, y=ll_cs)\n",
    "g = ax.set_xticklabels([f'10^{i}' for i in range(-10,10)])\n",
    "ax.set_xlabel('Regularization HyperParameter: C')\n",
    "ax.set_ylabel('Log Loss')\n",
    "ax.set_ylim([0.58, 0.605])\n",
    "g = plt.title('Log Loss Test Performance by Regularization Weight C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f2f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "x = np.log10(cs)\n",
    "\n",
    "sns.lineplot(x=x, y=acc_cs, marker='o')\n",
    "\n",
    "plt.title(\"Accuracy Test Performance by Regularization Weight C'\")\n",
    "plt.xlabel(\"Regularization HyperParameter: C\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the  Scikit-learn LogisticRegression model object below and assign to variable 'model_default'\n",
    "model_default = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "model_default.fit(X_train, y_train)\n",
    "\n",
    "# 1. Make predictions on the test data using the predict_proba() method\n",
    "proba_predictions_default = model_default.predict_proba(X_test)[:,1]\n",
    "\n",
    "# 2. Make predictions on the test data using the predict() method\n",
    "class_label_predictions_default = model_default.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706eead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, class_label_predictions_default, labels=[True,False]), columns=['Predicted: Arrival 20', 'Predicted: Not Arrival 20'],\n",
    "index=['Actual: Arrival 20', 'Actual: No Arrival 20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41199bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import l1_min_c\n",
    "\n",
    "cs = l1_min_c(X_train, y_train, loss=\"log\") * np.logspace(0, 7, 16)\n",
    "param_grid = dict(C = list(cs))\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b081c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "print('Running Grid Search...')\n",
    "\n",
    "# 1. Create a LogisticRegression model object with the argument max_iter=1000. \n",
    "#    Save the model object to the variable 'model'\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# 2. Run a grid search with 5-fold cross-validation and assign the output to the \n",
    "# object 'grid'.\n",
    "grid = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# 3. Fit the model on the training data and assign the fitted model to the \n",
    "#    variable 'grid_search'\n",
    "grid_search = grid.fit(X_train, y_train)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46de29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c = grid_search.best_params_\n",
    "best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d6a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the  model object below and assign to variable 'model_best'\n",
    "model_best = LogisticRegression(max_iter=1000, C = 6.106681900802449e-07)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "model_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make predictions on the test data using the predict_proba() method\n",
    "proba_predictions_best = model_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "# 2. Make predictions on the test data using the predict() method\n",
    "class_label_predictions_best = model_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e94f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, class_label_predictions_best, labels=[True,False]), columns=['Predicted: Arrival 20', 'Predicted: Not Arrival 20'],\n",
    "index=['Actual: Arrival 20', 'Actual: No Arrival 20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24bf335",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_default, recall_default, thresholds_default = precision_recall_curve(y_test, proba_predictions_default)\n",
    "precision_best, recall_best, thresholds_best = precision_recall_curve(y_test, proba_predictions_best)\n",
    "\n",
    "fpr_default, tpr_default, thresholds_default = roc_curve(y_test,proba_predictions_default)\n",
    "fpr_best, tpr_best, thresholds_best = roc_curve(y_test, proba_predictions_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ac450",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_default = auc(fpr_default, tpr_default)\n",
    "auc_best = auc(fpr_best, tpr_best)\n",
    "\n",
    "print(auc_default)\n",
    "print(auc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba176123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Note that k=5 is specifying that we want the top 5 features\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(X, y)\n",
    "filter = selector.get_support()\n",
    "top_5_features = X.columns[filter]\n",
    "\n",
    "print(\"Best 5 features:\")\n",
    "print(top_5_features)\n",
    "\n",
    "# Create new training and test data for features\n",
    "new_X_train = X_train[top_5_features]\n",
    "new_X_test = X_test[top_5_features]\n",
    "\n",
    "\n",
    "# Initialize a LogisticRegression model object with the best value of hyperparameter C \n",
    "# The model object should be named 'model'\n",
    "# Note: Supply max_iter=1000 as an argument when creating the model object\n",
    "model = LogisticRegression(max_iter=1000, C=2.7029857954888498e-05)\n",
    "\n",
    "\n",
    "# Fit the model to the new training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use the predict_proba() method to use your model to make predictions on the new test data \n",
    "# Save the values of the second column to a list called 'proba_predictions'\n",
    "proba_predictions = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    \n",
    "# Compute the auc-roc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, proba_predictions)\n",
    "auc_result = auc(fpr, tpr)\n",
    "print(auc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy much higher for arr_ind_20, lower log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list(df.iloc[:, 0:36].select_dtypes(include=\"float64\"))\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9cb44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:,\"arr_ind_1\"]\n",
    "X = df.loc[:,feature_list]\n",
    "\n",
    "print(\"Number of examples: \" + str(X.shape[0]))\n",
    "print(\"\\nNumber of Features:\" + str(X.shape[1]))\n",
    "print(str(list(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5709fb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = train_test_LR(X_train, y_train, X_test, y_test)\n",
    "print('Log loss: ' + str(loss))\n",
    "print('Accuracy: ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fce7297",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "x = np.log10(cs)\n",
    "\n",
    "sns.lineplot(x=x, y=acc_cs, marker='o')\n",
    "\n",
    "plt.title(\"Accuracy Test Performance by Regularization Weight C'\")\n",
    "plt.xlabel(\"Regularization HyperParameter: C\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8686a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the  Scikit-learn LogisticRegression model object below and assign to variable 'model_default'\n",
    "model_default = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "model_default.fit(X_train, y_train)\n",
    "\n",
    "# 1. Make predictions on the test data using the predict_proba() method\n",
    "proba_predictions_default = model_default.predict_proba(X_test)[:,1]\n",
    "\n",
    "# 2. Make predictions on the test data using the predict() method\n",
    "class_label_predictions_default = model_default.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the  model object below and assign to variable 'model_best'\n",
    "model_best = LogisticRegression(max_iter=1000, C = 6.106681900802449e-07)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "model_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b8ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make predictions on the test data using the predict_proba() method\n",
    "proba_predictions_best = model_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "# 2. Make predictions on the test data using the predict() method\n",
    "class_label_predictions_best = model_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b6fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, class_label_predictions_best, labels=[True,False]), columns=['Predicted: Arrival 1', 'Predicted: Not Arrival 1'],\n",
    "index=['Actual: Arrival 1', 'Actual: No Arrival 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd59bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_default, recall_default, thresholds_default = precision_recall_curve(y_test, proba_predictions_default)\n",
    "precision_best, recall_best, thresholds_best = precision_recall_curve(y_test, proba_predictions_best)\n",
    "\n",
    "fpr_default, tpr_default, thresholds_default = roc_curve(y_test,proba_predictions_default)\n",
    "fpr_best, tpr_best, thresholds_best = roc_curve(y_test, proba_predictions_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_default = auc(fpr_default, tpr_default)\n",
    "auc_best = auc(fpr_best, tpr_best)\n",
    "\n",
    "print(auc_default)\n",
    "print(auc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af622b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that k=5 is specifying that we want the top 5 features\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(X, y)\n",
    "filter = selector.get_support()\n",
    "top_5_features = X.columns[filter]\n",
    "\n",
    "print(\"Best 5 features:\")\n",
    "print(top_5_features)\n",
    "\n",
    "# Create new training and test data for features\n",
    "new_X_train = X_train[top_5_features]\n",
    "new_X_test = X_test[top_5_features]\n",
    "\n",
    "\n",
    "# Initialize a LogisticRegression model object with the best value of hyperparameter C \n",
    "# The model object should be named 'model'\n",
    "# Note: Supply max_iter=1000 as an argument when creating the model object\n",
    "model = LogisticRegression(max_iter=1000, C=2.7029857954888498e-05)\n",
    "\n",
    "\n",
    "# Fit the model to the new training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use the predict_proba() method to use your model to make predictions on the new test data \n",
    "# Save the values of the second column to a list called 'proba_predictions'\n",
    "proba_predictions = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    \n",
    "# Compute the auc-roc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, proba_predictions)\n",
    "auc_result = auc(fpr, tpr)\n",
    "print(auc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b6506",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list(df.iloc[:, 0:65].select_dtypes(include=\"float64\"))\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ffc9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:,\"arr_ind_30\"]\n",
    "X = df.loc[:,feature_list]\n",
    "\n",
    "print(\"Number of examples: \" + str(X.shape[0]))\n",
    "print(\"\\nNumber of Features:\" + str(X.shape[1]))\n",
    "print(str(list(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c0918",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = train_test_LR(X_train, y_train, X_test, y_test)\n",
    "print('Log loss: ' + str(loss))\n",
    "print('Accuracy: ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2745e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the  Scikit-learn LogisticRegression model object below and assign to variable 'model_default'\n",
    "model_default = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "model_default.fit(X_train, y_train)\n",
    "\n",
    "# 1. Make predictions on the test data using the predict_proba() method\n",
    "proba_predictions_default = model_default.predict_proba(X_test)[:,1]\n",
    "\n",
    "# 2. Make predictions on the test data using the predict() method\n",
    "class_label_predictions_default = model_default.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1734728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the  model object below and assign to variable 'model_best'\n",
    "model_best = LogisticRegression(max_iter=1000, C = 6.106681900802449e-07)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "model_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca5031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make predictions on the test data using the predict_proba() method\n",
    "proba_predictions_best = model_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "# 2. Make predictions on the test data using the predict() method\n",
    "class_label_predictions_best = model_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, class_label_predictions_best, labels=[True,False]), columns=['Predicted: Arrival 30', 'Predicted: Not Arrival 30'],\n",
    "index=['Actual: Arrival 30', 'Actual: No Arrival 30'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8d5e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_default, recall_default, thresholds_default = precision_recall_curve(y_test, proba_predictions_default)\n",
    "precision_best, recall_best, thresholds_best = precision_recall_curve(y_test, proba_predictions_best)\n",
    "\n",
    "fpr_default, tpr_default, thresholds_default = roc_curve(y_test,proba_predictions_default)\n",
    "fpr_best, tpr_best, thresholds_best = roc_curve(y_test, proba_predictions_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4a3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_default = auc(fpr_default, tpr_default)\n",
    "auc_best = auc(fpr_best, tpr_best)\n",
    "\n",
    "print(auc_default)\n",
    "print(auc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that k=5 is specifying that we want the top 5 features\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(X, y)\n",
    "filter = selector.get_support()\n",
    "top_5_features = X.columns[filter]\n",
    "\n",
    "print(\"Best 5 features:\")\n",
    "print(top_5_features)\n",
    "\n",
    "# Create new training and test data for features\n",
    "new_X_train = X_train[top_5_features]\n",
    "new_X_test = X_test[top_5_features]\n",
    "\n",
    "\n",
    "# Initialize a LogisticRegression model object with the best value of hyperparameter C \n",
    "# The model object should be named 'model'\n",
    "# Note: Supply max_iter=1000 as an argument when creating the model object\n",
    "model = LogisticRegression(max_iter=1000, C=2.7029857954888498e-05)\n",
    "\n",
    "\n",
    "# Fit the model to the new training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use the predict_proba() method to use your model to make predictions on the new test data \n",
    "# Save the values of the second column to a list called 'proba_predictions'\n",
    "proba_predictions = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    \n",
    "# Compute the auc-roc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, proba_predictions)\n",
    "auc_result = auc(fpr, tpr)\n",
    "print(auc_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
